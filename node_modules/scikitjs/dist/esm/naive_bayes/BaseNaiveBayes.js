/**
*  @license
* Copyright 2022, JsData. All rights reserved.
*
* This source code is licensed under the MIT license found in the
* LICENSE file in the root directory of this source tree.

* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
* ==========================================================================
*/
import { polyfillUnique } from '../tfUtils';
import { convertToNumericTensor2D, convertToTensor1D } from '../utils';
import { getBackend } from '../tf-singleton';
import { Serialize } from '../simpleSerializer';
export class BaseNaiveBayes extends Serialize {
    priors;
    varSmoothing;
    classes;
    means;
    variances;
    tf;
    constructor(params = {}) {
        super();
        this.tf = getBackend();
        this.classes = this.tf.tensor1d([]);
        this.means = [];
        this.variances = [];
        if (params.priors) {
            this.priors = convertToTensor1D(params.priors);
        }
        this.varSmoothing = params.varSmoothing ? params.varSmoothing : 1e-9;
    }
    /**
     * Train the model by calculating the mean and variance of sample distribution.
     * @param X
     * @param y
     * @returns
     */
    async fit(X, y) {
        const features = convertToNumericTensor2D(X);
        const labels = convertToTensor1D(y);
        const { values, meansByLabel, variancesByLabel } = this.tf.tidy(() => {
            polyfillUnique(this.tf);
            const meansByLabel = [];
            const variancesByLabel = [];
            // Get the list of unique labels
            const { values } = this.tf.unique(labels);
            const { variance } = this.tf.moments(features, 0);
            const epsilon = variance.max().mul(this.varSmoothing);
            this.tf.unstack(values).forEach((c) => {
                const mask = this.tf.equal(labels, c).toFloat();
                const numInstances = this.tf.sum(mask);
                const mean = this.tf
                    .mul(features, mask.expandDims(1))
                    .sum(0)
                    .div(numInstances);
                const variance = this.tf
                    .sub(features, mean)
                    .mul(mask.expandDims(1))
                    .pow(2)
                    .sum(0)
                    .div(numInstances)
                    .add(epsilon);
                meansByLabel.push(mean);
                variancesByLabel.push(variance);
            });
            return { values, meansByLabel, variancesByLabel };
        });
        // Unique labels this model have learned
        this.classes = values;
        this.means = meansByLabel;
        this.variances = variancesByLabel;
        return this;
    }
    /**
     * Predict the probability of samples assigned to each observed label.
     * @param X
     * @returns {this.tf.Tensor} Probabilities
     */
    predictProba(X) {
        const features = convertToNumericTensor2D(X);
        const probabilities = this.tf.tidy(() => {
            let probs = [];
            this.classes.unstack().forEach((_, idx) => {
                // Get the mean for this label
                const mean = this.means[idx];
                const variance = this.variances[idx];
                const prob = this.kernel(features, mean, variance);
                probs.push(prob);
            });
            const withoutPriors = this.tf.stack(probs, 1);
            if (this.priors) {
                return withoutPriors.mul(this.priors);
            }
            else {
                return withoutPriors;
            }
        });
        return probabilities;
    }
    /**
     * Predict the labels assigned to each sample
     * @param X
     * @returns {this.tf.Tensor} Labels
     */
    predict(X) {
        const probs = this.predictProba(X);
        return probs.argMax(1);
    }
}
