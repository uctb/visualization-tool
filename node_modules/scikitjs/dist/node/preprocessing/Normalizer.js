"use strict";
/**
*  @license
* Copyright 2021, JsData. All rights reserved.
*
* This source code is licensed under the MIT license found in the
* LICENSE file in the root directory of this source tree.

* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
* ==========================================================================
*/
Object.defineProperty(exports, "__esModule", { value: true });
exports.Normalizer = void 0;
const utils_1 = require("../utils");
const typesUtils_1 = require("../typesUtils");
const mixins_1 = require("../mixins");
const tf_singleton_1 = require("../tf-singleton");
/**
 * A Normalizer scales each *sample* by the $l_1$, $l_2$ or $max$ value in that sample.
 * If you imagine the input matrix as a 2D grid, then this is effectively a "horizontal" scaling (per-sample scaling)
 * as opposed to a StandardScaler which is a "vertical" scaling (per-feature scaling).
 *
 * The only input is what kind of norm you wish to scale by.
 *
 * @example
 * ```js
 * import { Normalizer } from 'scikitjs'
 *
 * const data = [
      [-1, 1],
      [-6, 6],
      [0, 10],
      [10, 20]
    ]
    const scaler = new Normalizer({ norm: 'l1' })
    const expected = scaler.fitTransform(scaler)
    const expectedValueAbove = [
      [-0.5, 0.5],
      [-0.5, 0.5],
      [0, 1],
      [0.33, 0.66]
    ]
 * ```
 */
class Normalizer extends mixins_1.TransformerMixin {
    norm;
    /** The number of features seen during fit */
    nFeaturesIn;
    /** Names of features seen during fit. Only stores feature names if input is a DataFrame */
    featureNamesIn;
    /** Useful for pipelines and column transformers to have a default name for transforms */
    name = 'Normalizer';
    constructor({ norm = 'l2' } = {}) {
        super();
        this.tf = (0, tf_singleton_1.getBackend)();
        this.norm = norm;
        this.nFeaturesIn = 0;
        this.featureNamesIn = [];
    }
    /**
     * Fits a Normalizer to the data
     */
    fit(X) {
        (0, typesUtils_1.assert)((0, typesUtils_1.isScikit2D)(X), 'Data can not be converted to a 2D matrix.');
        const tensorArray = (0, utils_1.convertToNumericTensor2D)(X);
        this.nFeaturesIn = tensorArray.shape[1];
        if ((0, typesUtils_1.isDataFrameInterface)(X)) {
            this.featureNamesIn = [...X.columns];
        }
        return this;
    }
    /**
     * Transform the data using the Normalizer
     * */
    transform(X) {
        (0, typesUtils_1.assert)((0, typesUtils_1.isScikit2D)(X), 'Data can not be converted to a 2D matrix.');
        const tensorArray = (0, utils_1.convertToNumericTensor2D)(X);
        if (this.norm === 'l1') {
            const means = this.tf.abs(tensorArray).sum(1).reshape([-1, 1]);
            return tensorArray.divNoNan(means);
        }
        if (this.norm === 'l2') {
            const means = tensorArray.square().sum(1).sqrt().reshape([-1, 1]);
            return tensorArray.divNoNan(means);
        }
        // max case
        const means = this.tf.abs(tensorArray).max(1).reshape([-1, 1]);
        return tensorArray.divNoNan(means);
    }
}
exports.Normalizer = Normalizer;
