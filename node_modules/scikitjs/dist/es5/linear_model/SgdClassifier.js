/**
*  @license
* Copyright 2021, JsData. All rights reserved.
*
* This source code is licensed under the MIT license found in the
* LICENSE file in the root directory of this source tree.

* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
* ==========================================================================
*/
var __extends = (this && this.__extends) || (function () {
    var extendStatics = function (d, b) {
        extendStatics = Object.setPrototypeOf ||
            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||
            function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };
        return extendStatics(d, b);
    };
    return function (d, b) {
        if (typeof b !== "function" && b !== null)
            throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
        extendStatics(d, b);
        function __() { this.constructor = d; }
        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    };
})();
var __assign = (this && this.__assign) || function () {
    __assign = Object.assign || function(t) {
        for (var s, i = 1, n = arguments.length; i < n; i++) {
            s = arguments[i];
            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))
                t[p] = s[p];
        }
        return t;
    };
    return __assign.apply(this, arguments);
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __generator = (this && this.__generator) || function (thisArg, body) {
    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;
    return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() { return this; }), g;
    function verb(n) { return function (v) { return step([n, v]); }; }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while (_) try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [op[0] & 2, t.value];
            switch (op[0]) {
                case 0: case 1: t = op; break;
                case 4: _.label++; return { value: op[1], done: false };
                case 5: _.label++; y = op[1]; op = [0]; continue;
                case 7: op = _.ops.pop(); _.trys.pop(); continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }
                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }
                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }
                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }
                    if (t[2]) _.ops.pop();
                    _.trys.pop(); continue;
            }
            op = body.call(thisArg, _);
        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }
        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };
    }
};
import { convertToNumericTensor1D_2D, convertToNumericTensor2D } from '../utils';
import { OneHotEncoder } from '../preprocessing/OneHotEncoder';
import { assert } from '../typesUtils';
import { ClassifierMixin } from '../mixins';
import { getBackend } from '../tf-singleton';
var SGDClassifier = /** @class */ (function (_super) {
    __extends(SGDClassifier, _super);
    function SGDClassifier(_a) {
        var modelFitArgs = _a.modelFitArgs, modelCompileArgs = _a.modelCompileArgs, denseLayerArgs = _a.denseLayerArgs, optimizerType = _a.optimizerType, lossType = _a.lossType;
        var _this = _super.call(this) || this;
        _this.tf = getBackend();
        _this.model = _this.tf.sequential();
        _this.modelFitArgs = modelFitArgs;
        _this.modelCompileArgs = modelCompileArgs;
        _this.denseLayerArgs = denseLayerArgs;
        _this.optimizerType = optimizerType;
        _this.lossType = lossType;
        _this.isMultiOutput = false;
        // Next steps: Implement "drop" mechanics for OneHotEncoder
        // There is a possibility to do a drop => if_binary which would
        // squash down on the number of variables that we'd have to learn
        _this.oneHot = new OneHotEncoder();
        return _this;
    }
    SGDClassifier.prototype.initializeModelForClassification = function (y) {
        var yToInt = y.toInt();
        // This covers the case of a dependent variable that is already one hot encoded.
        // There are other cases where you do "multi-variable output which isn't one hot encoded"
        // Like say you were predicting which diseases a person could have (hasCancer, hasMeningitis, etc)
        // Then you would have to run a sigmoid on each independent variable
        if (yToInt.shape.length === 2) {
            this.modelCompileArgs.loss = this.tf.losses.softmaxCrossEntropy;
            return yToInt;
        }
        else {
            var yTwoD = y.reshape([-1, 1]);
            var yTwoDOneHotEncoded = this.oneHot.fitTransform(yTwoD);
            if (this.oneHot.categories[0].length > 2) {
                this.modelCompileArgs.loss = this.tf.losses.softmaxCrossEntropy;
            }
            else {
                this.modelCompileArgs.loss = this.tf.losses.sigmoidCrossEntropy;
            }
            return yTwoDOneHotEncoded;
        }
    };
    /**
     * Creates the tensorflow model. Because the model contains only
     * one dense layer, we must pass the inputShape to that layer.
     * That inputShape is only known at "runtime" ie... when we call `fit(X, y)`
     * that first time. The inputShape is effectively `X.shape[1]`
     *
     * This function runs after that first call to fit or when pass in modelWeights.
     * That can come up if we train a model in python, and simply want to copy over the
     * weights to this JS version so we can deploy on browsers / phones.
     * @returns {void}
     */
    SGDClassifier.prototype.initializeModel = function (X, y, weightsTensors) {
        if (weightsTensors === void 0) { weightsTensors = []; }
        this.denseLayerArgs.units = y.shape.length === 1 ? 1 : y.shape[1];
        var model = this.tf.sequential();
        model.add(this.tf.layers.dense(__assign({ inputShape: [X.shape[1]] }, this.denseLayerArgs)));
        model.compile(this.modelCompileArgs);
        if (weightsTensors === null || weightsTensors === void 0 ? void 0 : weightsTensors.length) {
            model.setWeights(weightsTensors);
        }
        this.model = model;
    };
    /**
     * Similar to scikit-learn, this trains a model to predict y, from X.
     * Even in the case where we predict a single output vector,
     * the predictions are a 2D matrix (albeit a single column in a 2D Matrix).
     *
     * This is to facilitate the case where we predict multiple targets, or in the case
     * of classification where we are predicting a 2D Matrix of probability class labels.
     * @param {Scikit2D} X The 2DTensor / 2D Array that you wish to use as a training matrix
     * @param {ScikitVecOrMatrix} y Either 1D or 2D array / Tensor that you wish to predict
     *
     * @returns {Promise<SGD>} Returns the predictions.
     *
     * We use a LinearRegression in the example below because it provides
     * defaults for the SGD
     *
     * @example
     *
     * lr = new LinearRegression()
     * await lr.fit(X, y);
     * // lr model weights have been updated
     */
    SGDClassifier.prototype.fit = function (X, y) {
        return __awaiter(this, void 0, void 0, function () {
            var XTwoD, yOneD, yTwoD;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        XTwoD = convertToNumericTensor2D(X);
                        yOneD = convertToNumericTensor1D_2D(y);
                        yTwoD = this.initializeModelForClassification(yOneD);
                        if (yOneD.shape.length > 1) {
                            this.isMultiOutput = true;
                        }
                        if (this.model.layers.length === 0) {
                            this.initializeModel(XTwoD, yTwoD);
                        }
                        return [4 /*yield*/, this.model.fit(XTwoD, yTwoD, __assign({}, this.modelFitArgs))];
                    case 1:
                        _a.sent();
                        return [2 /*return*/, this];
                }
            });
        });
    };
    /**
     * This aims to be a bridge to scikit-learn Estimators, where users can train
     * models over in scikit-learn and then ship the coefficients into the proper
     * Estimator on the Scikit.js side. This can be useful if the python version is faster
     * to train, but we still need a JS version because we wish to ship to mobile or browsers.
     *
     * @param {{ coef: number[]; intercept: number }} params The object that contains the model parameters,
     * coef, and intercept that we need for our model.
     *
     * @returns {SGD} Returns the predictions.
     *
     * We use a LinearRegression in the example below because it provides
     * defaults for the SGD
     *
     * @example
     *
     * lr = new LinearRegression()
     * lr.importModel({coef : [1.2, 2.3], intercept: 10.0});
     * // lr model weights have been updated
     */
    SGDClassifier.prototype.importModel = function (params) {
        // Next steps: Need to update for possible 2D coef case, and 1D intercept case
        var myCoef = this.tf.tensor2d(params.coef, [params.coef.length, 1], 'float32');
        var myIntercept = this.tf.tensor1d([params.intercept], 'float32');
        this.initializeModel(myCoef, myIntercept, [myCoef, myIntercept]);
        return this;
    };
    /**
     * Similar to scikit-learn, this returns the object of configuration params for SGD
     * @returns {SGDClassifierParams} Returns an object of configuration params.
     *
     * We use a LinearRegression in the example below because it provides
     * defaults for the SGD
     *
     * @example
     *
     * lr = new LinearRegression()
     * lr.getParams()
     * // =>
      {
        modelCompileArgs: {
          optimizer: train.adam(0.1),
          loss: losses.meanSquaredError,
          metrics: ['mse'],
        },
        modelFitArgs: {
          batchSize: 32,
          epochs: 1000,
          verbose: 0,
          callbacks: [callbacks.earlyStopping({ monitor: 'mse', patience: 50 })],
        },
        denseLayerArgs: {
          units: 1,
          useBias: true,
        }
      }
     */
    SGDClassifier.prototype.getParams = function () {
        return {
            modelFitArgs: this.modelFitArgs,
            modelCompileArgs: this.modelCompileArgs,
            denseLayerArgs: this.denseLayerArgs,
            optimizerType: this.optimizerType,
            lossType: this.lossType
        };
    };
    /**
     * Similar to scikit-learn, this returns the object of configuration params for SGD
     * @returns {SGDClassifierParams} Returns an object of configuration params.
     *
     * We use a LinearRegression in the example below because it provides
     * defaults for the SGD
     *
     * @example
     *
     * lr = new LinearRegression()
     * lr.setParams({
        modelFitArgs: {
          batchSize: 100,
          epochs: -1,
          verbose: 1,
        })
     */
    SGDClassifier.prototype.setParams = function (params) {
        this.modelCompileArgs = params.modelCompileArgs;
        this.modelFitArgs = params.modelFitArgs;
        this.denseLayerArgs = params.denseLayerArgs;
        return this;
    };
    SGDClassifier.prototype.predictProba = function (X) {
        assert(this.model.layers.length > 0, 'Need to call "fit" before "predict"');
        var XTwoD = convertToNumericTensor2D(X);
        return this.model.predict(XTwoD);
    };
    /**
     * Similar to scikit-learn, this returns a Tensor2D (2D Matrix) of predictions.
     * Even in the case where we predict a single output vector,
     * the predictions are a 2D matrix (albeit a single column in a 2D Matrix).
     *
     * This is to facilitate the case where we predict multiple targets, or in the case
     * of classification where we are predicting a 2D Matrix of probability class labels.
     * @param {Scikit2D} X The 2DTensor / 2D Array that you wish to run through
     * your model and make predictions.
     *
     * @returns {Tensor2D} Returns the predictions.
     *
     * We use a LinearRegression in the example below because it provides
     * defaults for the SGD
     *
     * @example
     *
     * lr = new LinearRegression()
     * await lr.fit(X, y);
     * lr.predict(X)
     * // => tensor2d([[ 4.5, 10.3, 19.1, 0.22 ]])
     */
    SGDClassifier.prototype.predict = function (X) {
        assert(this.model.layers.length > 0, 'Need to call "fit" before "predict"');
        var y2D = this.predictProba(X);
        if (this.isMultiOutput) {
            return this.tf.oneHot(y2D.argMax(1), y2D.shape[1]);
        }
        return this.tf.tensor1d(this.oneHot.inverseTransform(y2D));
    };
    Object.defineProperty(SGDClassifier.prototype, "coef", {
        /**
         * Similar to scikit-learn, this returns the coefficients of our linear model.
         * The return type is a 1D matrix (technically a Tensor1D) if we predict a single output.
         * It's a 2D matrix (Tensor2D) if we predict a regression task with multiple outputs or
         * a classification task with multiple class labels.
         * @returns {Tensor1D | Tensor2D} Returns the coefficients.
         *
         * We use a LinearRegression in the example below because it provides
         * defaults for the SGD
         *
         * @example
         *
         * lr = new LinearRegression()
         * await lr.fit(X, [1,2,3]);
         * lr.coef
         * // => tensor1d([[ 1.2, 3.3, 1.1, 0.2 ]])
         *
         * await lr.fit(X, [ [1,2], [3,4], [5,6] ]);
         * lr.coef
         * // => tensor2d([ [1.2, 3.3], [3.4, 5.6], [4.5, 6.7] ])
      
         */
        get: function () {
            var modelWeights = this.model.getWeights();
            if (modelWeights.length === 0) {
                return this.tf.tensor2d([]);
            }
            var coefficients = modelWeights[0];
            if (coefficients.shape[1] === 1) {
                return coefficients.reshape([coefficients.shape[0]]);
            }
            return coefficients;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(SGDClassifier.prototype, "intercept", {
        /**
         * Similar to scikit-learn, this returns the intercept of our linear model.
         * The return type is always a Tensor1D (a vector).
         * Normally we'd just return a single number but in the case
         * of multiple regression (multiple output targets) we'd need
         * a vector to store all the intercepts,
         * @returns {number | Tensor1D} Returns the intercept.
         *
         * We use a LinearRegression in the example below because it provides
         * defaults for the SGD
         *
         * @example
         *
         * lr = new LinearRegression()
         * await lr.fit(X, [1,2,3]);
         * lr.intercept
         * // => 4.5
         *
         *
         * lr = new LinearRegression()
         * await lr.fit(X, [ [1,2,3], [4,5,6] ]);
         * lr.intercept
         * // => tensor1d([1.2, 2.3])
         */
        get: function () {
            var modelWeights = this.model.getWeights();
            if (modelWeights.length < 2) {
                return 0.0;
            }
            var intercept = modelWeights[1];
            if (intercept.size === 1) {
                return intercept.arraySync()[0];
            }
            return intercept;
        },
        enumerable: false,
        configurable: true
    });
    return SGDClassifier;
}(ClassifierMixin));
export { SGDClassifier };
