var __read = (this && this.__read) || function (o, n) {
    var m = typeof Symbol === "function" && o[Symbol.iterator];
    if (!m) return o;
    var i = m.call(o), r, ar = [], e;
    try {
        while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);
    }
    catch (error) { e = { error: error }; }
    finally {
        try {
            if (r && !r.done && (m = i["return"])) m.call(i);
        }
        finally { if (e) throw e.error; }
    }
    return ar;
};
import { getBackend } from '../tf-singleton';
export var makeRegression = function (_a) {
    var _b = _a === void 0 ? {} : _a, _c = _b.nSamples, nSamples = _c === void 0 ? 100 : _c, _d = _b.nFeatures, nFeatures = _d === void 0 ? 100 : _d, _e = _b.nInformative, nInformative = _e === void 0 ? 10 : _e, _f = _b.nTargets, nTargets = _f === void 0 ? 1 : _f, _g = _b.noise, noise = _g === void 0 ? 1 : _g, _h = _b.bias, bias = _h === void 0 ? 0 : _h, _j = _b.effectiveRank, effectiveRank = _j === void 0 ? null : _j, _k = _b.tailStrength, tailStrength = _k === void 0 ? 0.5 : _k, _l = _b.shuffle, shuffle = _l === void 0 ? false : _l, _m = _b.coef, coef = _m === void 0 ? false : _m;
    var tf = getBackend();
    return tf.tidy(function () {
        var numberInformative = Math.min(nFeatures, nInformative);
        var X;
        if (effectiveRank === null) {
            // Randomly generate a well conditioned input set
            X = tf.randomNormal([nSamples, nFeatures]);
        }
        else {
            X = makeLowRankMatrix({
                nSamples: nSamples,
                nFeatures: nFeatures,
                effectiveRank: effectiveRank,
                tailStrength: tailStrength
            });
        }
        // Generate a ground truth model with only n_informative features being non
        // zeros (the other features are not correlated to y and should be ignored
        // by a sparsifying regularizers such as L1 or elastic net)
        var model = tf.randomNormal([numberInformative, nTargets]).mul(100);
        var zeros = tf.zeros([nFeatures - numberInformative, nTargets]);
        var groundTruth = tf.concat([model, zeros]);
        var Y = X.dot(groundTruth).add(bias);
        // Add noise
        if (noise > 0) {
            Y = Y.add(tf.randomNormal(Y.shape, undefined, noise));
        }
        // Randomly permute samples and features
        if (shuffle) {
            var randomTen = tf.util.createShuffledIndices(nSamples);
            X = X.gather(randomTen);
        }
        Y = tf.squeeze(Y);
        if (coef) {
            return [X, Y, tf.squeeze(groundTruth)];
        }
        return [X, Y];
    });
};
export var makeLowRankMatrix = function (_a) {
    var _b = _a === void 0 ? {} : _a, _c = _b.nSamples, nSamples = _c === void 0 ? 100 : _c, _d = _b.nFeatures, nFeatures = _d === void 0 ? 100 : _d, _e = _b.effectiveRank, effectiveRank = _e === void 0 ? 10 : _e, _f = _b.tailStrength, tailStrength = _f === void 0 ? 0.5 : _f;
    var tf = getBackend();
    return tf.tidy(function () {
        var n = Math.min(nSamples, nFeatures);
        // Random (ortho normal) vectors
        var _a = __read(tf.linalg.qr(tf.randomNormal([nSamples, n])), 1), u = _a[0];
        var _b = __read(tf.linalg.qr(tf.randomNormal([nFeatures, n])), 1), v = _b[0];
        // Index of the singular values
        var singularIndex = tf.range(0, n);
        // Build the singular profile by assembling signal and noise components
        var singularIndexByRank = singularIndex.div(effectiveRank);
        var lowRank = tf
            .exp(singularIndexByRank.square().neg())
            .mul(1 - tailStrength);
        var tail = tf.exp(singularIndexByRank.mul(-0.1)).mul(tailStrength);
        var s = lowRank.add(tail);
        return u.mul(s).dot(v.transpose());
    });
};
